{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7Ic1xc9rimg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Implement a transformer architecture and improve and analyze it's arous aspects rather than focus on a particular paper\n",
    "\n",
    "Use percentage changes as data source instead of prices\n",
    "\n",
    "If we make a predictor which just guesses next day's price as the same as todayâ€™s price, it would have better than 95% accuracy. \n",
    "\n",
    "Guessing whether next day price will go up or down i.e. as a classification problem."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#W&B Setup\n",
    "!pip install wandb\n",
    "import wandb"
   ],
   "metadata": {
    "id": "eTXysHkqLKIy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "kEwuEgTyI7Bf",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ace78037-c35e-44fb-ede5-2c4e9a4a17ac"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "/content/drive/MyDrive/WB_Projects/Demo\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "drive.mount(\"/content/drive\")\n",
    "%cd '/content/drive/MyDrive/WB_Projects/Demo/'  "
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3vQ7yk7Z2IF3",
    "outputId": "5ec98aed-ab51-4c9d-c8ae-d8066b4e83b6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wed Apr 27 01:13:12 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   42C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#Increase RAM Usage\n",
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KgtNuTaj2OqL",
    "outputId": "b057ad5f-4691-42eb-e3b6-bf4c301bcd84",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Your runtime has 27.3 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from utils.get_dataset import GetDataset, StockData\n",
    "from torch.utils.data import DataLoader"
   ],
   "metadata": {
    "id": "rbH2c1ucncAo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def build_dataset(num_days, batch_size):\n",
    "\n",
    "  NUM_DAYS = num_days\n",
    "  KEEP_CLOSE_ONLY = False # debug to drop other columns\n",
    "\n",
    "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "  csv = '../data/SPXDailyData.csv'\n",
    "  df = GetDataset(csv)\n",
    "  dataset = df.get_data()\n",
    "\n",
    "  #split into 3\n",
    "  valid_frac, test_frac = 0.2, 0.2\n",
    "  train_sz=int(dataset.shape[0]*(1-(valid_frac+test_frac)))\n",
    "  valid_sz=int(dataset.shape[0]*(valid_frac))\n",
    "  df_train = dataset[               0:train_sz]\n",
    "  df_valid = dataset[        train_sz:train_sz+valid_sz]\n",
    "  df_test = dataset[train_sz+valid_sz:]\n",
    "\n",
    "  if KEEP_CLOSE_ONLY:# see in case additional info acts like a noise\n",
    "    df_train.drop(columns=['Open', 'High', 'Low'], inplace=True)\n",
    "    df_valid.drop(columns=['Open', 'High', 'Low'], inplace=True)\n",
    "    df_test.drop(columns=['Open', 'High', 'Low'], inplace=True)\n",
    "\n",
    "  train_dataset = StockData(df_train.to_numpy(), num_days=NUM_DAYS)\n",
    "  valid_dataset = StockData(df_valid.to_numpy(), num_days=NUM_DAYS) \n",
    "  test_dataset = StockData(df_test.to_numpy(), num_days=NUM_DAYS)\n",
    " \n",
    "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "  valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False) \n",
    "\n",
    "  return train_loader, valid_loader,  test_dataset"
   ],
   "metadata": {
    "id": "eiNpuxC6knoM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "3q-ItwbSI7B5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from utils.utils import plot_curves\n",
    "from utils.utils import train\n",
    "from utils.utils import evaluate\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import math\n",
    "import copy"
   ],
   "metadata": {
    "id": "anmkWlBKlPIS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "\n",
    "warnings.warn = warn"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "vBC0IgBjI7B6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Import Model\n",
    "from models.my_transformer import TransformerModelImpl"
   ],
   "metadata": {
    "id": "PUT08iAHtPXq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train_model(config=None): #Configs \n",
    "    with wandb.init(config=config): #https://docs.wandb.ai/guides/track/launch\n",
    "      # This config will be set by Sweep Controller # https://docs.wandb.ai/guides/sweeps/quickstart\n",
    "      config = wandb.config\n",
    "\n",
    "      #Generate Train/Validation Loaders and Test Dataset\n",
    "      train_loader, valid_loader, test_dataset = build_dataset(config.n_days, config.batch_size)\n",
    "\n",
    "      #Initialize Model\n",
    "      model = TransformerModelImpl(config)\n",
    "\n",
    "      #Set optimizer and loss function\n",
    "      optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "      criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "\n",
    "      device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "      model.float()\n",
    "      model.to(device) #Set model to utilizie available device\n",
    "\n",
    "      #Dataframes for tracking results\n",
    "      avg_train_loss,avg_train_acc,avg_valid_loss,avg_valid_acc=[],[],[],[]\n",
    "\n",
    "      for epoch in range(config.epochs):\n",
    "          train_loss, atl, ata = train(model, train_loader, optimizer, criterion, device)\n",
    "          #scheduler.step(train_loss)\n",
    "          _, avl, ava = evaluate(model, valid_loader, criterion, device)\n",
    "          if epoch%50==1:\n",
    "            print(\"Epoch %d: Training Loss: %.4f. Training Acc: %.4f. Validation Loss: %.4f. Validation Acc: %.4f.\" % (epoch+1, atl, ata, avl, ava))\n",
    "          avg_train_loss.append(atl.item())\n",
    "          avg_train_acc.append(ata)\n",
    "          avg_valid_loss.append(avl.item())\n",
    "          avg_valid_acc.append(ava)\n",
    "          #Weights and biases logging: Reference: https://docs.wandb.ai/guides/track/log\n",
    "          wandb.log({\"train-loss\": atl, \"epoch\": epoch})\n",
    "          wandb.log({\"validation-loss\": avl, \"epoch\": epoch})\n",
    "          wandb.log({\"train-acc\":ata, \"epoch\": epoch})\n",
    "          wandb.log({\"validation-acc\": ava, \"epoch\": epoch})\n",
    "\n",
    "      #Plot training/loss curves             \n",
    "      plot_curves(avg_train_loss,avg_train_acc,avg_valid_loss,avg_valid_acc, info='', save=False)   \n",
    "      #mfinal = copy.deepcopy(model)\n",
    "    "
   ],
   "metadata": {
    "id": "fTYuSvmZpv0I",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Configure Sweep Parameters\n",
    "#https://docs.wandb.ai/guides/sweeps/quickstart#2.-configure-your-sweep\n",
    "sweep_config = {\n",
    "    'method': 'bayes', \n",
    "    'metric': {'goal': 'minimize', 'name': 'train-loss'},\n",
    "    'early_terminate': { 'type': 'hyperband', 's': 2, 'eta': 3,'max_iter': 27}\n",
    "    }\n",
    "\n",
    "parameters_dict = {\n",
    "    'device': {\n",
    "       'values': torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    },\n",
    "    'n_days' :{\n",
    "        'values': [5,10]\n",
    "    },\n",
    "     'n_layers': {\n",
    "        'distribution': 'int_uniform',\n",
    "        'min': 1,\n",
    "        'max': 16\n",
    "    },\n",
    "    'num_heads': {\n",
    "        'distribution': 'int_uniform',\n",
    "        'min': 1,\n",
    "        'max':6\n",
    "    },\n",
    "    'forward_dim': {\n",
    "      'distribution': 'int_uniform',\n",
    "      'min': 2,\n",
    "      'max': 16,\n",
    "    },\n",
    "    'output_dim':{\n",
    "        'values': [1] \n",
    "    },\n",
    "    'model_dim': {\n",
    "        'values': [4]\n",
    "    },\n",
    "    'dropout': {\n",
    "        'values':[0.1,0.2,0.3]\n",
    "    },\n",
    "    'lr': {\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0,\n",
    "        'max': 0.1\n",
    "    },    \n",
    "    'epochs' :{\n",
    "      'distribution': 'int_uniform',\n",
    "      'min': 5,\n",
    "      'max': 30,      \n",
    "    },\n",
    "    'batch_size':{\n",
    "      'distribution': 'int_uniform',\n",
    "      'min': 4,\n",
    "      'max': 16,      \n",
    "    },\n",
    "\n",
    "}\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict #Set Configs"
   ],
   "metadata": {
    "id": "UmhvSzhNlPpK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "wandb_project_name = \"FinanceTransformer-R1\" #User Choice\n",
    "\n",
    "#Initialize a hyperparameter sweep. \n",
    "#https://docs.wandb.ai/ref/python/sweep\n",
    "sweep_id = wandb.sweep(sweep_config, project = wandb_project_name)\n",
    "\n",
    "#Run Client\n",
    "#https://docs.wandb.ai/ref/python/agent\n",
    "wandb.agent(sweep_id, train_model)"
   ],
   "metadata": {
    "id": "Qcf1-3VvWjXM",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "outputId": "e41369e7-2ef8-4155-ca16-150f64d564ee",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Create sweep with ID: ycienwz9\n",
      "Sweep URL: https://wandb.ai/mohammadbakir/FinanceTransformer-R1/sweeps/ycienwz9\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Agent Starting Run: arbghcas with config:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tbatch_size: 14\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tdevice: cuda\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tdropout: 0.2\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tepochs: 12\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tforward_dim: 13\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tlr: 0.013765332185026914\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tmodel_dim: 4\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tn_days: 5\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tn_layers: 4\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tnum_heads: 2\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \toutput_dim: 1\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/content/drive/MyDrive/WB_Projects/Demo/wandb/run-20220427_012718-arbghcas</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mohammadbakir/FinanceTransformer-R1/runs/arbghcas\" target=\"_blank\">easy-sweep-1</a></strong> to <a href=\"https://wandb.ai/mohammadbakir/FinanceTransformer-R1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/mohammadbakir/FinanceTransformer-R1/sweeps/ycienwz9\" target=\"_blank\">https://wandb.ai/mohammadbakir/FinanceTransformer-R1/sweeps/ycienwz9</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## References\n",
    "\n",
    "Great Youtube Video On Basic Usage & Walk through Colab Link\n",
    "\n",
    "*   https://www.youtube.com/watch?v=G7GH0SeNBMA\n",
    "*   https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Simple_PyTorch_Integration.ipynb\n"
   ],
   "metadata": {
    "id": "WTtkD-XMjQuv",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "KyhAZ6x6nw2f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "exp.ipynb",
   "provenance": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}